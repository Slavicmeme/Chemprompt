{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4900a266-7d24-42de-be3a-f97d083e9d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b251d41-3ade-44c2-89e4-dd743bb6c769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from Chemprompt.data.data_loader import DataLoader\n",
    "from Chemprompt.models.sklearn_model import ScikitLearnModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd3fa1d-5957-4be2-9e61-a4239c3c8b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset & models\n",
    "dataset_list = [\"FreeSolv\", \"Caco2_Wang\"]\n",
    "model_list = [\n",
    "    {\"repo\": \"seyonec\", \"name\": \"ChemBERTa-zinc-base-v1\"},\n",
    "    {\"repo\": \"ibm-research\", \"name\": \"MoLFormer-XL-both-10pct\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7753e332-d575-4869-91bc-26cd20453dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083a8130-bf54-42a0-8a00-95b28572821d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(smiles_list, repo, name, device=\"cuda:0\"):\n",
    "    model_id = f\"{repo}/{name}\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "    model = AutoModel.from_pretrained(model_id, trust_remote_code=True, use_safetensors=True).to(device)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(smiles_list, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "        outputs = model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47e499ab-5dee-46b6-9347-117d137293cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(642, 2)\n",
      "Processing dataset=FreeSolv, model=ChemBERTa-zinc-base-v1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at seyonec/ChemBERTa-zinc-base-v1 and are newly initialized: ['embeddings.word_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to ./result/BERT/ChemBERTa-zinc-base-v1/FreeSolv/regression_Predictions.csv\n",
      "Combined results saved to ./result/BERT/ChemBERTa-zinc-base-v1/FreeSolv/regression_CombinedResults.csv\n",
      "Processing dataset=FreeSolv, model=MoLFormer-XL-both-10pct ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to ./result/BERT/MoLFormer-XL-both-10pct/FreeSolv/regression_Predictions.csv\n",
      "Combined results saved to ./result/BERT/MoLFormer-XL-both-10pct/FreeSolv/regression_CombinedResults.csv\n",
      "(1128, 2)\n",
      "Processing dataset=ESOL, model=ChemBERTa-zinc-base-v1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at seyonec/ChemBERTa-zinc-base-v1 and are newly initialized: ['embeddings.word_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to ./result/BERT/ChemBERTa-zinc-base-v1/ESOL/regression_Predictions.csv\n",
      "Combined results saved to ./result/BERT/ChemBERTa-zinc-base-v1/ESOL/regression_CombinedResults.csv\n",
      "Processing dataset=ESOL, model=MoLFormer-XL-both-10pct ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to ./result/BERT/MoLFormer-XL-both-10pct/ESOL/regression_Predictions.csv\n",
      "Combined results saved to ./result/BERT/MoLFormer-XL-both-10pct/ESOL/regression_CombinedResults.csv\n",
      "(1400, 2)\n",
      "Processing dataset=rand_lipo, model=ChemBERTa-zinc-base-v1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at seyonec/ChemBERTa-zinc-base-v1 and are newly initialized: ['embeddings.word_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to ./result/BERT/ChemBERTa-zinc-base-v1/rand_lipo/regression_Predictions.csv\n",
      "Combined results saved to ./result/BERT/ChemBERTa-zinc-base-v1/rand_lipo/regression_CombinedResults.csv\n",
      "Processing dataset=rand_lipo, model=MoLFormer-XL-both-10pct ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to ./result/BERT/MoLFormer-XL-both-10pct/rand_lipo/regression_Predictions.csv\n",
      "Combined results saved to ./result/BERT/MoLFormer-XL-both-10pct/rand_lipo/regression_CombinedResults.csv\n",
      "('HPPB', (1614, 2))\n",
      "Processing dataset=HPPB, model=ChemBERTa-zinc-base-v1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at seyonec/ChemBERTa-zinc-base-v1 and are newly initialized: ['embeddings.word_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to ./result/BERT/ChemBERTa-zinc-base-v1/HPPB/regression_Predictions.csv\n",
      "Combined results saved to ./result/BERT/ChemBERTa-zinc-base-v1/HPPB/regression_CombinedResults.csv\n",
      "Processing dataset=HPPB, model=MoLFormer-XL-both-10pct ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to ./result/BERT/MoLFormer-XL-both-10pct/HPPB/regression_Predictions.csv\n",
      "Combined results saved to ./result/BERT/MoLFormer-XL-both-10pct/HPPB/regression_CombinedResults.csv\n",
      "('Thermosol', (1763, 2))\n",
      "Processing dataset=Thermosol, model=ChemBERTa-zinc-base-v1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at seyonec/ChemBERTa-zinc-base-v1 and are newly initialized: ['embeddings.word_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to ./result/BERT/ChemBERTa-zinc-base-v1/Thermosol/regression_Predictions.csv\n",
      "Combined results saved to ./result/BERT/ChemBERTa-zinc-base-v1/Thermosol/regression_CombinedResults.csv\n",
      "Processing dataset=Thermosol, model=MoLFormer-XL-both-10pct ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to ./result/BERT/MoLFormer-XL-both-10pct/Thermosol/regression_Predictions.csv\n",
      "Combined results saved to ./result/BERT/MoLFormer-XL-both-10pct/Thermosol/regression_CombinedResults.csv\n"
     ]
    }
   ],
   "source": [
    "for dataset in dataset_list:\n",
    "    smiles_list, y = loader.load_dataset(dataset)\n",
    "\n",
    "    for m in model_list:\n",
    "        model_name = m[\"name\"]\n",
    "        print(f\"Processing dataset={dataset}, model={model_name} ...\")\n",
    "\n",
    "        # get embeddings\n",
    "        X = get_embeddings(smiles_list, m[\"repo\"], model_name, device=\"cuda:0\")\n",
    "\n",
    "        # ScikitLearnModel\n",
    "        save_dir = f\"./result/BERT/{model_name}/{dataset}/\"\n",
    "        sk_model = ScikitLearnModel(model_type=\"regression\", save_dir=save_dir)\n",
    "        sk_model.fit_and_evaluate_fold(smiles_list, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88844af3-bd91-465c-9af5-0329acf4e9b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
