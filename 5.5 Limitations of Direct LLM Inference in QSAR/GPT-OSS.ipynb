{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f93c217f-e310-4a35-871a-285670d1cd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abe1c60b-b3be-4d8e-9808-1c11cfc4651d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No normalization for SPS. Feature removed!\n",
      "No normalization for AvgIpc. Feature removed!\n",
      "Skipped loading some Tensorflow models, missing a dependency. No module named 'tensorflow'\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch_geometric'\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. cannot import name 'DMPNN' from 'deepchem.models.torch_models' (/HDD1/bbq9088/miniconda3/envs/ChEmPrompt1027/lib/python3.10/site-packages/deepchem/models/torch_models/__init__.py)\n",
      "Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'lightning'\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n",
      "Skipped loading some PyTorch models, missing a dependency. No module named 'tensorflow'\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "from collections import defaultdict\n",
    "from Chemprompt.data.data_loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "054967ee-2fda-4dcb-b8a6-fdc0e6b42d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress RDKit warnings\n",
    "from rdkit import Chem\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog(\"rdApp.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27a9beed-0f98-4bf0-a728-361b4f3250ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The checkpoint you are trying to load has model type `gpt_oss` but Transformers does not recognize this architecture. This could be because of an issue with the checkpoint, or because your version of Transformers is out of date.\n\nYou can update Transformers with the command `pip install --upgrade transformers`. If this does not work, and the checkpoint is very new, then there may not be a release version that supports this model yet. In this case, you can get the most up-to-date code by installing Transformers from source with the command `pip install git+https://github.com/huggingface/transformers.git`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/HDD1/bbq9088/miniconda3/envs/ChEmPrompt1027/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:1113\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1112\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1113\u001b[0m     config_class \u001b[38;5;241m=\u001b[39m \u001b[43mCONFIG_MAPPING\u001b[49m\u001b[43m[\u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m/HDD1/bbq9088/miniconda3/envs/ChEmPrompt1027/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:815\u001b[0m, in \u001b[0;36m_LazyConfigMapping.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mapping:\n\u001b[0;32m--> 815\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    816\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mapping[key]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'gpt_oss'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m load_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_repo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(load_model)\n\u001b[0;32m----> 6\u001b[0m pipe \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext-generation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfloat16\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# bfloat16\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# cuda:0\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/HDD1/bbq9088/miniconda3/envs/ChEmPrompt1027/lib/python3.10/site-packages/transformers/pipelines/__init__.py:851\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    848\u001b[0m                 adapter_path \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m    849\u001b[0m                 model \u001b[38;5;241m=\u001b[39m adapter_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase_model_name_or_path\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 851\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[43mAutoConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_from_pipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode_revision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_revision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    854\u001b[0m     hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39m_commit_hash\n\u001b[1;32m    856\u001b[0m custom_tasks \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/HDD1/bbq9088/miniconda3/envs/ChEmPrompt1027/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:1115\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1113\u001b[0m         config_class \u001b[38;5;241m=\u001b[39m CONFIG_MAPPING[config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m   1114\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m-> 1115\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1116\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe checkpoint you are trying to load has model type `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1117\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut Transformers does not recognize this architecture. This could be because of an \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1118\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124missue with the checkpoint, or because your version of Transformers is out of date.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1119\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can update Transformers with the command `pip install --upgrade transformers`. If this \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1120\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not work, and the checkpoint is very new, then there may not be a release version \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1121\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthat supports this model yet. In this case, you can get the most up-to-date code by installing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1122\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformers from source with the command \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1123\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip install git+https://github.com/huggingface/transformers.git`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1124\u001b[0m         )\n\u001b[1;32m   1125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m config_class\u001b[38;5;241m.\u001b[39mfrom_dict(config_dict, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwargs)\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1127\u001b[0m     \u001b[38;5;66;03m# Fallback: use pattern matching on the string.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m     \u001b[38;5;66;03m# We go from longer names to shorter names to catch roberta before bert (for instance)\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: The checkpoint you are trying to load has model type `gpt_oss` but Transformers does not recognize this architecture. This could be because of an issue with the checkpoint, or because your version of Transformers is out of date.\n\nYou can update Transformers with the command `pip install --upgrade transformers`. If this does not work, and the checkpoint is very new, then there may not be a release version that supports this model yet. In this case, you can get the most up-to-date code by installing Transformers from source with the command `pip install git+https://github.com/huggingface/transformers.git`"
     ]
    }
   ],
   "source": [
    "# Load GPT-OSS model (cuda:0, bfloat16)\n",
    "model_id = \"openai/gpt-oss-20b\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0c10f2-8c9e-40d6-885c-9b740d54b89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prompt(smiles: str, dataset_name: str) -> str:\n",
    "    if smiles is None:\n",
    "        return \"\"  # Invalid SMILES\n",
    "        \n",
    "    if dataset_name == \"FreeSolv\":\n",
    "        task = \"Predict the solvation free energy in water for the molecule below.\"\n",
    "    elif dataset_name == \"ESOL\":\n",
    "        task = \"Predict the aqueous solubility (logS) for the molecule below.\"\n",
    "    elif dataset_name == \"Lipo\":\n",
    "        task = \"Predict the lipophilicity (logP) for the molecule below.\"\n",
    "    elif dataset_name == \"HPPB\":\n",
    "        task = \"Predict the human plasma protein binding (%PPB) for the molecule below.\"\n",
    "    elif dataset_name == \"Caco2_Wang\":\n",
    "        task = \"Predict the Caco-2 cell permeability (logPapp) for the molecule below.\"\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "    rules = (\n",
    "        \"Return a single numeric prediction (float).\\n\"\n",
    "        \"Output EXACTLY one number on its own line.\\n\"\n",
    "        \"No units. No words. No labels. No extra text.\\n\"\n",
    "        \"Use '.' as the decimal separator. Scientific notation allowed.\\n\"\n",
    "    )\n",
    "\n",
    "    return f\"Human: {task}\\n{rules}Molecule (SMILES): {smiles}\\nAssistant:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bcb867-d6db-4919-8674-611d469d1823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_number(text: str):\n",
    "    if not text:\n",
    "        return None\n",
    "\n",
    "    for line in text.splitlines():\n",
    "        line = line.strip()\n",
    "        if re.fullmatch(r\"[-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?\", line):\n",
    "            return float(line)\n",
    "\n",
    "    matches = re.findall(r\"[-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?\", text)\n",
    "    return float(matches[-1]) if matches else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55d6453-b706-4b31-9d7a-acdd70c4dd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [\"Caco2_Wang\"]\n",
    "loader = DataLoader()\n",
    "\n",
    "base_output_dir = f\"./result/QandA/{model_id.split('/')[-1]}\"\n",
    "os.makedirs(base_output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1d3018-5df0-487d-a000-18bf4bb4d57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in tqdm(dataset_names, desc=\"Dataset\"):\n",
    "    print(f\"\\n[+] Processing dataset: {dataset_name}\")\n",
    "\n",
    "    x, y = loader.load_dataset(dataset_name)\n",
    "    x, y = np.array(x), np.array(y)\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    fold_results = []\n",
    "    metrics_per_fold = defaultdict(list)\n",
    "    skipped_records = []\n",
    "\n",
    "    output_dir = os.path.join(base_output_dir, dataset_name)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    answer_txt_path = os.path.join(output_dir, f\"{dataset_name}_answers.txt\")\n",
    "    skipped_csv_path = os.path.join(output_dir, f\"{dataset_name}_skipped_samples.csv\")\n",
    "\n",
    "    open(answer_txt_path, \"w\").close()\n",
    "\n",
    "    # =========================\n",
    "    # Cross-validation\n",
    "    # =========================\n",
    "    for fold, (_, test_idx) in enumerate(kf.split(x), start=1):\n",
    "        x_test, y_test = x[test_idx], y[test_idx]\n",
    "        predictions = []\n",
    "\n",
    "        for i, smiles in enumerate(tqdm(x_test, desc=f\"Fold {fold}\", leave=False), start=1):\n",
    "            prompt = format_prompt(smiles, dataset_name)\n",
    "            if not prompt:\n",
    "                predictions.append(None)\n",
    "                skipped_records.append({\"fold\": fold, \"index\": i, \"smiles\": str(smiles)})\n",
    "                continue\n",
    "\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": \"You are a scientific regression model. Output exactly one float.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "\n",
    "            outputs = pipe(\n",
    "                messages,\n",
    "                max_new_tokens=32767,\n",
    "                do_sample=False,\n",
    "            )\n",
    "\n",
    "            reply = outputs[0][\"generated_text\"][-1][\"content\"].strip()\n",
    "\n",
    "            with open(answer_txt_path, \"a\") as f:\n",
    "                f.write(reply + \"\\n\")\n",
    "                f.write(\"=\" * 50 + \"\\n\")\n",
    "\n",
    "            pred = extract_number(reply)\n",
    "            if pred is None:\n",
    "                skipped_records.append({\"fold\": fold, \"index\": i, \"smiles\": str(smiles)})\n",
    "\n",
    "            predictions.append(pred)\n",
    "\n",
    "        # =========================\n",
    "        # Fold results\n",
    "        # =========================\n",
    "        df_fold = pd.DataFrame({\n",
    "            \"smiles\": list(x_test),\n",
    "            \"true_value\": list(y_test),\n",
    "            \"predicted_value\": list(predictions),\n",
    "            \"fold\": fold\n",
    "        })\n",
    "        fold_results.append(df_fold)\n",
    "\n",
    "        df_valid = df_fold.dropna(subset=[\"predicted_value\"])\n",
    "        y_true = df_valid[\"true_value\"].astype(float).values\n",
    "        y_pred = df_valid[\"predicted_value\"].astype(float).values\n",
    "\n",
    "        # =========================\n",
    "        # Metrics (NaN-safe)\n",
    "        # =========================\n",
    "        rmse = np.sqrt(mean_squared_error(y_true, y_pred)) if len(y_pred) > 0 else np.nan\n",
    "        r2 = r2_score(y_true, y_pred) if len(y_pred) > 0 else np.nan\n",
    "        pcc = pearsonr(y_true, y_pred)[0] if len(y_pred) >= 2 else np.nan\n",
    "        spearman = spearmanr(y_true, y_pred)[0] if len(y_pred) >= 2 else np.nan\n",
    "\n",
    "        metrics_per_fold[\"Fold\"].append(fold)\n",
    "        metrics_per_fold[\"RMSE\"].append(rmse)\n",
    "        metrics_per_fold[\"R2\"].append(r2)\n",
    "        metrics_per_fold[\"PCC\"].append(pcc)\n",
    "        metrics_per_fold[\"SPEARMAN\"].append(spearman)\n",
    "\n",
    "    # =========================\n",
    "    # Save predictions\n",
    "    # =========================\n",
    "    df_all = pd.concat(fold_results, ignore_index=True)\n",
    "    df_all.to_csv(os.path.join(output_dir, f\"{dataset_name}_predictions.csv\"), index=False)\n",
    "\n",
    "    if skipped_records:\n",
    "        pd.DataFrame(skipped_records).to_csv(skipped_csv_path, index=False)\n",
    "    else:\n",
    "        with open(skipped_csv_path, \"w\") as f:\n",
    "            f.write(\"No skipped samples\\n\")\n",
    "\n",
    "    # =========================\n",
    "    # Save metrics\n",
    "    # =========================\n",
    "    df_metrics = pd.DataFrame(metrics_per_fold)\n",
    "\n",
    "    metric_cols = [\"RMSE\", \"R2\", \"PCC\", \"SPEARMAN\"]\n",
    "    mean_row = df_metrics[metric_cols].mean()\n",
    "    std_row = df_metrics[metric_cols].std()\n",
    "\n",
    "    mean_df = pd.DataFrame([[\"mean\"] + mean_row.tolist()], columns=df_metrics.columns)\n",
    "    std_df = pd.DataFrame([[\"std\"] + std_row.tolist()], columns=df_metrics.columns)\n",
    "\n",
    "    df_metrics = pd.concat([df_metrics, mean_df, std_df], ignore_index=True)\n",
    "    df_metrics.to_csv(os.path.join(output_dir, \"combined_metrics.csv\"), index=False)\n",
    "\n",
    "    # =========================\n",
    "    # Save short summary\n",
    "    # =========================\n",
    "    with open(os.path.join(output_dir, \"metrics.txt\"), \"w\") as f:\n",
    "        for k in metric_cols:\n",
    "            f.write(f\"{k}: {mean_row[k]:.3f}\\n\")\n",
    "\n",
    "    print(f\"[âœ“] Saved results to {output_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
